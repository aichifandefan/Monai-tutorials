{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Activations, EnsureChannelFirst, AsDiscrete, Compose, RandRotate90, RandSpatialCrop, ScaleIntensity\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = 'Temp_dataset'\n",
    "# 随机生成40个数据 大小为(128, 128, 128) 分割类别为1\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"im{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取图像和分割的路径\n",
    "images = sorted(glob(os.path.join(tempdir, \"im*.nii.gz\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集图像和分割的变化操作\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),           # 将输入图像的强度放大到给定的值范围 默认为(0,1)之间\n",
    "        EnsureChannelFirst(),       # 调整或增加输入数据的通道维数 确保第一维为通道维度\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),       # 随机裁剪图像固定块的大小 random_size=False 输入图像小于roi维度将不会被裁剪\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),            # 随机旋转图像概率为0.5， spatial_axes=（0，2） 在第一维和第三维组成的平面上进行旋转\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        EnsureChannelFirst(),\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测集图像和分割的变化操作\n",
    "val_imtrans = Compose([ScaleIntensity(), EnsureChannelFirst()])\n",
    "val_segtrans = Compose([EnsureChannelFirst()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据加载器\n",
    "train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预测数据加载器\n",
    "val_ds = ImageDataset(images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建平均dice评价指标， get_not_nans 是否返回not nans 的个数\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)     \n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 UNet, DiceLoss 和 Adam 优化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/5\n",
      "1/5, train_loss: 0.6528\n",
      "2/5, train_loss: 0.6035\n",
      "3/5, train_loss: 0.5523\n",
      "4/5, train_loss: 0.5589\n",
      "5/5, train_loss: 0.5027\n",
      "epoch 1 average loss: 0.5740\n",
      "----------\n",
      "epoch 2/5\n",
      "1/5, train_loss: 0.5185\n",
      "2/5, train_loss: 0.5524\n",
      "3/5, train_loss: 0.4978\n",
      "4/5, train_loss: 0.4990\n",
      "5/5, train_loss: 0.4820\n",
      "epoch 2 average loss: 0.5099\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.5774 best mean dice: 0.5774 at epoch 2\n",
      "----------\n",
      "epoch 3/5\n",
      "1/5, train_loss: 0.5014\n",
      "2/5, train_loss: 0.4777\n",
      "3/5, train_loss: 0.4466\n",
      "4/5, train_loss: 0.4978\n",
      "5/5, train_loss: 0.4914\n",
      "epoch 3 average loss: 0.4830\n",
      "----------\n",
      "epoch 4/5\n",
      "1/5, train_loss: 0.4648\n",
      "2/5, train_loss: 0.4874\n",
      "3/5, train_loss: 0.4355\n",
      "4/5, train_loss: 0.4689\n",
      "5/5, train_loss: 0.5098\n",
      "epoch 4 average loss: 0.4733\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.9042 best mean dice: 0.9042 at epoch 4\n",
      "----------\n",
      "epoch 5/5\n",
      "1/5, train_loss: 0.4755\n",
      "2/5, train_loss: 0.4222\n",
      "3/5, train_loss: 0.4470\n",
      "4/5, train_loss: 0.4402\n",
      "5/5, train_loss: 0.4665\n",
      "epoch 5 average loss: 0.4503\n",
      "train completed, best_metric: 0.9042 at epoch: 4\n"
     ]
    }
   ],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(5):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{5}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (96, 96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
